{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy([\"/gpu:0\"])\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "num_replicas = strategy.num_replicas_in_sync\n",
    "\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_src_image = tf.keras.Input(shape=image_shape)\n",
    "\t# target image input\n",
    "\tin_target_image = tf.keras.Input(shape=image_shape)\n",
    "\t# concatenate images channel-wise\n",
    "\tmerged = tf.keras.layers.Concatenate()([in_src_image, in_target_image])\n",
    "\t# C64\n",
    "\td = tf.keras.layers.Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = tf.keras.layers.Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = tf.keras.layers.BatchNormalization()(d)\n",
    "\td = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = tf.keras.layers.Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = tf.keras.layers.BatchNormalization()(d)\n",
    "\td = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "\t# C512\n",
    "\td = tf.keras.layers.Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = tf.keras.layers.BatchNormalization()(d)\n",
    "\td = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "\t# second last output layer\n",
    "\td = tf.keras.layers.Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = tf.keras.layers.BatchNormalization()(d)\n",
    "\td = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\td = tf.keras.layers.Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = tf.keras.layers.Activation('sigmoid')(d)\n",
    "\t# define model\n",
    "\tmodel = tf.keras.Model([in_src_image, in_target_image], patch_out)\n",
    "\t# compile model\n",
    "\t#opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "\t#model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model\n",
    "\n",
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "\t# weight initialization\n",
    "\tinit = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "\t# add downsampling layer\n",
    "\tg = tf.keras.layers.Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# conditionally add batch normalization\n",
    "\tif batchnorm:\n",
    "\t\tg = tf.keras.layers.BatchNormalization()(g, training=True)\n",
    "\t# leaky relu activation\n",
    "\tg = tf.keras.layers.LeakyReLU(alpha=0.2)(g)\n",
    "\treturn g\n",
    "\n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\t# weight initialization\n",
    "\tinit = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "\t# add upsampling layer\n",
    "\tg = tf.keras.layers.Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# add batch normalization\n",
    "\tg = tf.keras.layers.BatchNormalization()(g, training=True)\n",
    "\t# conditionally add dropout\n",
    "\tif dropout:\n",
    "\t\tg = tf.keras.layers.Dropout(0.5)(g, training=True)\n",
    "\t# merge with skip connection\n",
    "\tg = tf.keras.layers.Concatenate()([g, skip_in])\n",
    "\t# relu activation\n",
    "\tg = tf.keras.layers.Activation('relu')(g)\n",
    "\treturn g\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,256,3)):\n",
    "\t# weight initialization\n",
    "\tinit = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "\t# image input\n",
    "\tin_image = tf.keras.layers.Input(shape=image_shape)\n",
    "\t# encoder model\n",
    "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "\te2 = define_encoder_block(e1, 128)\n",
    "\te3 = define_encoder_block(e2, 256)\n",
    "\te4 = define_encoder_block(e3, 512)\n",
    "\te5 = define_encoder_block(e4, 512)\n",
    "\te6 = define_encoder_block(e5, 512)\n",
    "\te7 = define_encoder_block(e6, 512)\n",
    "\t# bottleneck, no batch norm and relu\n",
    "\tb = tf.keras.layers.Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "\tb = tf.keras.layers.Activation('relu')(b)\n",
    "\t# decoder model\n",
    "\td1 = decoder_block(b, e7, 512)\n",
    "\td2 = decoder_block(d1, e6, 512)\n",
    "\td3 = decoder_block(d2, e5, 512)\n",
    "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\t# output\n",
    "\tg = tf.keras.layers.Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\tout_image = tf.keras.layers.Activation('tanh')(g)\n",
    "\t# define model\n",
    "\tmodel = tf.keras.Model(in_image, out_image)\n",
    "\treturn model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# define the source image\n",
    "\tin_src = tf.keras.Input(shape=image_shape)\n",
    "\t# connect the source image to the generator input\n",
    "\tgen_out = g_model(in_src)\n",
    "\t# connect the source input and generator output to the discriminator input\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\t# src image as input, generated image and classification output\n",
    "\tmodel = tf.keras.Model(in_src, [dis_out, gen_out])\n",
    "\t# compile model\n",
    "\t#opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "\t#model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model\n",
    "\n",
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "\t# load compressed arrays\n",
    "\tdata = load(filename)\n",
    "\t# unpack arrays\n",
    "\tX1, X2 = data['arr_0'], data['arr_1']\n",
    "\tX1Train, X2Train = X1[0:int(len(X1)*0.5)],X2[0:int(len(X2)*0.5)]\n",
    "\tX1Valid, X2Valid = X1[int(len(X1)*0.5):],X2[int(len(X2)*0.5):]\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX1Train = (X1Train - 127.5) / 127.5\n",
    "\tX2Train = (X2Train - 127.5) / 127.5\n",
    "\tX1Valid = (X1Valid - 127.5) / 127.5\n",
    "\tX2Valid = (X2Valid - 127.5) / 127.5\n",
    "\treturn [X1Train, X2Train, X1Valid, X2Valid]\n",
    "\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "\t# unpack dataset\n",
    "\ttrainA, trainB, validA, validB  = dataset\n",
    "\t# choose random instances\n",
    "\tix = randint(0, trainA.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\t#X1, X2 = trainA[tf.gather_nd(ix)], trainB[tf.convert_to_tensor(ix)]\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y\n",
    "\n",
    "def evaluate_real_samples(dataset, n_samples, patch_shape):\n",
    "\t# unpack dataset\n",
    "\ttrainA, trainB, validA, validB  = dataset\n",
    "\t# choose random instances\n",
    "\t#207 247 183 [ 207  247 183]\n",
    "\t#ix = randint(0, trainA.shape[0], n_samples)\n",
    "\tprint(\"Fixed images\")\n",
    "\t# retrieve selected images\n",
    "\t#X1, X2 = trainA[tf.gather_nd(ix)], trainB[tf.convert_to_tensor(ix)]\n",
    "\tX1, X2 = validA[0:int(len(validA))], validB[0:int(len(validA))]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\t# generate fake instance\n",
    "\tX = g_model.predict(samples)\n",
    "\t#X = g_model(samples)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, dataset, n_epochs, n_batch, n_samples):\n",
    "\tprint(\"summarize\")\n",
    "\t# select a sample of input images\n",
    "\t[X_realA, X_realB], _ = evaluate_real_samples(dataset, n_samples, 1)\n",
    "\t# generate a batch of fake samples\n",
    "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\t# scale all pixels from [-1,1] to [0,1]\n",
    "\tX_realA = (X_realA + 1) / 2.0\n",
    "\tX_realB = (X_realB + 1) / 2.0\n",
    "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
    "\torigin_path = \"multi_plot_origin_%d_%d\" % (n_epochs, n_batch)\n",
    "\tprediction_path = \"multi_plot_prediction_%d_%d\" % (n_epochs, n_batch)\n",
    "\tlabel_path = \"multi_plot_label_%d_%d\" % (n_epochs, n_batch)\n",
    "\taccess_rights = 0o777\n",
    "\tos.umask(0)\n",
    "\tos.mkdir(origin_path, access_rights)\n",
    "\tos.mkdir(prediction_path, access_rights)\n",
    "\tos.mkdir(label_path, access_rights)\n",
    "\t# plot real source images\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_realA[i])\n",
    "\t\tfilename1 = '%d_multi_plot_origin_%d_%d.png' % (i, n_epochs, n_batch)\n",
    "\t\tpyplot.savefig(origin_path + \"/\" + filename1)\n",
    "\t\tpyplot.close()\n",
    "\t# plot generated target image\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_fakeB[i])\n",
    "\t\tfilename2 = '%d_multi_plot_prediction_%d_%d.png' % (i, n_epochs, n_batch)\n",
    "\t\tpyplot.savefig(prediction_path + \"/\" + filename2)\n",
    "\t\tpyplot.close()\n",
    "\t# plot real target image\n",
    "\tfor i in range(n_samples):\n",
    "\t\tpyplot.axis('off')\n",
    "\t\tpyplot.imshow(X_realB[i])\n",
    "\t\tfilename3 = '%d_multi_plot_label_%d_%d.png' % (i, n_epochs, n_batch)\n",
    "\t\tpyplot.savefig(label_path + \"/\" + filename3)\n",
    "\t\tpyplot.close()\n",
    "\t# save the generator model\n",
    "\tfilename4 = 'multi_model_%d_%d.h5' % (n_epochs, n_batch)\n",
    "\tg_model.save(filename4)\n",
    "\tprint('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_discriminator_on_batch(d_model, g_model, X_realA, X_realB, real=True):    \n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        if real == True:\n",
    "            output = d_model([X_realA, X_realB], training = True)            \n",
    "        else:\n",
    "            #generate a batch of fake samples\n",
    "            X_fakeB = g_model(X_realA)        \n",
    "            output = d_model([X_realA, X_fakeB], training = True)\n",
    "\n",
    "        #Calculate discriminator loss        \n",
    "        d_loss = discriminator_loss(output, real)\n",
    "    \n",
    "    #Update the descriminator\n",
    "    gradients_of_discriminator = disc_tape.gradient(d_loss, d_model.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, d_model.trainable_variables))\n",
    "    \n",
    "    return d_loss\n",
    "\n",
    "@tf.function\n",
    "def train_generator_on_batch(d_model, g_model, X_realA, X_realB):\n",
    "               \n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        gen_out = g_model(X_realA)\n",
    "        dis_out = d_model([X_realA, gen_out])        \n",
    "        g_loss  = generator_loss(dis_out, gen_out, X_realB)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(g_loss, g_model.trainable_variables) \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, g_model.trainable_variables))\n",
    "\n",
    "    return g_loss\n",
    "\n",
    "    #tf.print('real_output:')\n",
    "    #tf.print(real_output)\n",
    "    #tf.print('fake_output:') \n",
    "    #tf.print(fake_output)\n",
    "    #tf.print('g_loss:')\n",
    "    #tf.print(g_loss)\n",
    "    #tf.print('d1_loss:') \n",
    "    #tf.print(d1_loss)\n",
    "    #tf.print('gradients_of_generator')\n",
    "    #tf.print(gradients_of_generator)\n",
    "    #tf.print('gradients_of_discriminator')\n",
    "    #tf.print(gradients_of_discriminator)\n",
    "\n",
    "# prediction of 0 = fake, 1 = real\n",
    "@tf.function\n",
    "def discriminator_loss(output, real):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    if real==True:\n",
    "        per_example_losses = bce(tf.ones_like(output), output)\n",
    "    else:\n",
    "        per_example_losses = bce(tf.zeros_like(output), output)\n",
    "    \n",
    "    loss=tf.reduce_sum(per_example_losses)*(1.0/256)*(1.0/batch_size)\n",
    "\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def generator_loss(fake_output, X_fakeB, X_realB):\n",
    "    \n",
    "    bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    per_example_losses = bce(tf.ones_like(fake_output), fake_output) \n",
    "    lbl_loss = tf.reduce_sum(per_example_losses)*(1.0/256)*(1.0/batch_size)\n",
    "    \n",
    "    mae_img = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    per_img_losses = mae_img(X_realB, X_fakeB)\n",
    "    iloss = tf.reduce_sum(per_img_losses)*(1.0 /256.0)*(1.0/256.0)*(1.0/batch_size)\n",
    "\n",
    "    return (lbl_loss + (100.0*iloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (548, 256, 256, 3) (548, 256, 256, 3) (548, 256, 256, 3) (548, 256, 256, 3)\n",
      "INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function discriminator_loss at 0x7fffa5aa0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function discriminator_loss at 0x7fffa5aa0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function discriminator_loss at 0x7fffa5aa0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function discriminator_loss at 0x7fffa5aa0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 58 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 58 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      ">0, d1_loss=0.613, d2_loss = 0.657, gen_loss=59.984\n",
      ">1, d1_loss=0.141, d2_loss = 0.257, gen_loss=41.001\n",
      ">2, d1_loss=0.072, d2_loss = 0.060, gen_loss=25.124\n",
      ">3, d1_loss=0.624, d2_loss = 0.322, gen_loss=16.408\n",
      ">4, d1_loss=0.031, d2_loss = 0.023, gen_loss=12.330\n",
      ">5, d1_loss=0.023, d2_loss = 0.017, gen_loss=11.797\n",
      ">6, d1_loss=0.018, d2_loss = 0.012, gen_loss=11.116\n",
      ">7, d1_loss=0.014, d2_loss = 0.009, gen_loss=10.778\n",
      ">8, d1_loss=0.011, d2_loss = 0.007, gen_loss=10.540\n",
      ">9, d1_loss=0.009, d2_loss = 0.006, gen_loss=11.014\n",
      ">10, d1_loss=0.008, d2_loss = 0.005, gen_loss=10.063\n",
      ">11, d1_loss=0.007, d2_loss = 0.004, gen_loss=9.766\n",
      ">12, d1_loss=0.006, d2_loss = 0.003, gen_loss=9.714\n",
      ">13, d1_loss=0.006, d2_loss = 0.003, gen_loss=9.518\n",
      ">14, d1_loss=0.006, d2_loss = 0.003, gen_loss=9.663\n",
      ">15, d1_loss=0.005, d2_loss = 0.003, gen_loss=9.099\n",
      ">16, d1_loss=0.005, d2_loss = 0.002, gen_loss=8.964\n",
      ">17, d1_loss=0.004, d2_loss = 0.002, gen_loss=8.979\n",
      ">18, d1_loss=0.004, d2_loss = 0.002, gen_loss=8.975\n",
      ">19, d1_loss=0.003, d2_loss = 0.002, gen_loss=9.173\n",
      ">20, d1_loss=0.003, d2_loss = 0.002, gen_loss=8.517\n",
      ">21, d1_loss=0.003, d2_loss = 0.002, gen_loss=8.460\n",
      ">22, d1_loss=0.003, d2_loss = 0.001, gen_loss=8.370\n",
      ">23, d1_loss=0.003, d2_loss = 0.001, gen_loss=8.333\n",
      ">24, d1_loss=0.002, d2_loss = 0.001, gen_loss=8.171\n",
      ">25, d1_loss=0.002, d2_loss = 0.001, gen_loss=8.003\n",
      ">26, d1_loss=0.002, d2_loss = 0.001, gen_loss=9.932\n",
      ">27, d1_loss=0.002, d2_loss = 0.001, gen_loss=8.205\n",
      ">28, d1_loss=0.002, d2_loss = 0.001, gen_loss=7.965\n",
      ">29, d1_loss=0.002, d2_loss = 0.001, gen_loss=7.963\n",
      ">30, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.841\n",
      ">31, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.799\n",
      ">32, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.668\n",
      ">33, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.683\n",
      ">34, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.751\n",
      ">35, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.561\n",
      ">36, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.484\n",
      ">37, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.443\n",
      ">38, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.408\n",
      ">39, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.386\n",
      ">40, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.320\n",
      ">41, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.295\n",
      ">42, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.505\n",
      ">43, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.212\n",
      ">44, d1_loss=0.001, d2_loss = 0.001, gen_loss=7.170\n",
      ">45, d1_loss=0.001, d2_loss = 0.000, gen_loss=7.132\n",
      ">46, d1_loss=0.001, d2_loss = 0.000, gen_loss=7.355\n",
      ">47, d1_loss=0.001, d2_loss = 0.000, gen_loss=7.166\n",
      ">48, d1_loss=0.001, d2_loss = 0.000, gen_loss=7.173\n",
      ">49, d1_loss=0.001, d2_loss = 0.000, gen_loss=7.078\n",
      "summarize\n",
      "Fixed images\n",
      "Saved\n",
      "312.9258782863617\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    # load image data\n",
    "    dataset = np.array(load_real_samples('/cwsshare/data/yunl/SatelliateToMap/data/maps/maps_256.npz'))\n",
    "    print('Loaded', dataset[0].shape, dataset[1].shape, dataset[2].shape, dataset[3].shape)\n",
    "    # define input shape based on the loaded dataset\n",
    "    image_shape = dataset[0].shape[1:]\n",
    "    # define the models\n",
    "    d_model = define_discriminator(image_shape)\n",
    "    g_model = define_generator(image_shape)\n",
    "    # define the composite model\n",
    "    #gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n",
    "    generator_optimizer =  tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "    trainA, trainB, validA, validB = dataset\n",
    "    datasetA = tf.data.Dataset.from_tensor_slices(trainA)\n",
    "    datasetB = tf.data.Dataset.from_tensor_slices(trainB)\n",
    "    datasetA = datasetA.cache()\n",
    "    datasetB = datasetB.cache()\n",
    "    datasetA = datasetA.batch(batch_size, drop_remainder=True)\n",
    "    datasetB = datasetB.batch(batch_size, drop_remainder=True)\n",
    "    datasetA = datasetA.prefetch(1)\n",
    "    datasetB = datasetB.prefetch(1)\n",
    "\n",
    "    datasetA = strategy.experimental_distribute_dataset(datasetA)\n",
    "    datasetB = strategy.experimental_distribute_dataset(datasetB)\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        for batchA, batchB in zip(datasetA, datasetB):\n",
    "            d1_loss = strategy.experimental_run_v2(train_discriminator_on_batch, args=(d_model, g_model, batchA, batchB))\n",
    "            d2_loss = strategy.experimental_run_v2(train_discriminator_on_batch, args=(d_model, g_model, batchA, batchB, False))\n",
    "            g_loss = strategy.experimental_run_v2(train_generator_on_batch, args=(d_model, g_model, batchA, batchB))\n",
    "            \n",
    "            d1_loss = (strategy.reduce(tf.distribute.ReduceOp.SUM, d1_loss, axis=None))\n",
    "            d2_loss = (strategy.reduce(tf.distribute.ReduceOp.SUM, d2_loss, axis=None))\n",
    "            g_loss = (strategy.reduce(tf.distribute.ReduceOp.SUM, g_loss, axis=None))\n",
    "            \n",
    "        print('>%d, d1_loss=%.3f, d2_loss = %.3f, gen_loss=%.3f' % (i, d1_loss, d2_loss, g_loss))\n",
    "    summarize_performance(i, g_model, dataset, n_epochs, batch_size, int(len(validA)))\n",
    "\n",
    "end = time.time()\n",
    "print (str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
